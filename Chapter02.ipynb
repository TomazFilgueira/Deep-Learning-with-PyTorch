{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TomazFilgueira/Deep-Learning-with-PyTorch/blob/main/Chapter02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PP0AqGM4ZkXf"
      },
      "source": [
        "# Deep Learning with PyTorch Step-by-Step: A Beginner's Guide"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6sXGerzZkXg"
      },
      "source": [
        "# Chapter 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qkUOWehzZkXh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d5a0cd9-5496-484a-ee79-a0b4a6fbad15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading files from GitHub repo to Colab...\n",
            "Finished!\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    import google.colab\n",
        "    import requests\n",
        "    url = 'https://raw.githubusercontent.com/dvgodoy/PyTorchStepByStep/master/config.py'\n",
        "    r = requests.get(url, allow_redirects=True)\n",
        "    open('config.py', 'wb').write(r.content)\n",
        "except ModuleNotFoundError:\n",
        "    pass\n",
        "\n",
        "from config import *\n",
        "config_chapter2()\n",
        "# This is needed to render the plots in this chapter\n",
        "from plots.chapter2 import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "bQ0gWDzTZkXh"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
        "from torch.utils.data.dataset import random_split\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.style.use('fivethirtyeight')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cxAWnY5oZkXh"
      },
      "source": [
        "# Rethinking the Training Loop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i9_BBtdlZkXh"
      },
      "source": [
        "### Model Training V0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "aPgCPPY_ZkXi"
      },
      "outputs": [],
      "source": [
        "# Runs data generation - so we do not need to copy code here\n",
        "%run -i data_generation/simple_linear_regression.py\n",
        "\n",
        "# Runs the first two parts of the sequence: data preparation and model configuration\n",
        "%run -i data_preparation/v0.py\n",
        "%run -i model_configuration/v0.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "gwIAeU-kZkXi"
      },
      "outputs": [],
      "source": [
        "# %load model_training/v0.py\n",
        "\n",
        "# Defines number of epochs\n",
        "n_epochs = 1000\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    # Sets model to TRAIN mode\n",
        "    model.train()\n",
        "\n",
        "    # Step 1 - Computes our model's predicted output - forward pass\n",
        "    # No more manual prediction!\n",
        "    yhat = model(x_train_tensor)\n",
        "\n",
        "    # Step 2 - Computes the loss\n",
        "    loss = loss_fn(yhat, y_train_tensor)\n",
        "\n",
        "    # Step 3 - Computes gradients for both \"a\" and \"b\" parameters\n",
        "    loss.backward()\n",
        "\n",
        "    # Step 4 - Updates parameters using gradients and the learning rate\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "DBIE6yvRZkXi",
        "outputId": "89e74dcf-04ae-4799-80fa-35d7fccf34b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OrderedDict([('0.weight', tensor([[1.9690]], device='cuda:0')), ('0.bias', tensor([1.0235], device='cuda:0'))])\n"
          ]
        }
      ],
      "source": [
        "print(model.state_dict())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ObGDAECZkXi"
      },
      "source": [
        "## Higher-Order Functions\n",
        "\n",
        "High-Order Functions são funcões construtoras de outras funções.\n",
        "\n",
        "Uma **função** que retorna outras **funções**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "nunzMxiKZkXi"
      },
      "outputs": [],
      "source": [
        "def square(x):\n",
        "    return x ** 2\n",
        "\n",
        "def cube(x):\n",
        "    return x ** 3\n",
        "\n",
        "def fourth_power(x):\n",
        "    return x ** 4\n",
        "\n",
        "# and so on and so forth..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "G3QrAr1dZkXi"
      },
      "outputs": [],
      "source": [
        "def generic_exponentiation(x, exponent):\n",
        "    return x ** exponent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "vqHYIsM8ZkXi"
      },
      "outputs": [],
      "source": [
        "def skeleton_exponentiation(x):\n",
        "    return x ** exponent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "bpR6uTqtZkXj",
        "outputId": "23ea833a-3af2-4540-98d6-9c8a161abc26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'exponent' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/content/model_configuration/v0.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mskeleton_exponentiation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/model_configuration/v0.py\u001b[0m in \u001b[0;36mskeleton_exponentiation\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mskeleton_exponentiation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0mexponent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'exponent' is not defined"
          ]
        }
      ],
      "source": [
        "skeleton_exponentiation(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S7HLN1crZkXj"
      },
      "outputs": [],
      "source": [
        "def exponentiation_builder(exponent):\n",
        "    def skeleton_exponentiation(x):\n",
        "        return x ** exponent\n",
        "\n",
        "    return skeleton_exponentiation"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Uma função que retorna outra função"
      ],
      "metadata": {
        "id": "7JPE3WAodOoM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0xIdCQ4nZkXj"
      },
      "outputs": [],
      "source": [
        "returned_function = exponentiation_builder(2)\n",
        "\n",
        "returned_function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6moup65MZkXj"
      },
      "outputs": [],
      "source": [
        "returned_function(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r0oY596XZkXj"
      },
      "outputs": [],
      "source": [
        "square = exponentiation_builder(2)\n",
        "cube = exponentiation_builder(3)\n",
        "fourth_power = exponentiation_builder(4)\n",
        "\n",
        "# and so on and so forth..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4gA8eMmZkXj"
      },
      "source": [
        "### Helper Function #1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "z7UOyxRvZkXj"
      },
      "outputs": [],
      "source": [
        "def make_train_step_fn(model, loss_fn, optimizer):\n",
        "    # Builds function that performs a step in the train loop\n",
        "    def perform_train_step_fn(x, y):\n",
        "        # Sets model to TRAIN mode\n",
        "        model.train()\n",
        "\n",
        "        # Step 1 - Computes our model's predicted output - forward pass\n",
        "        yhat = model(x)\n",
        "        # Step 2 - Computes the loss\n",
        "        loss = loss_fn(yhat, y)\n",
        "        # Step 3 - Computes gradients for both \"a\" and \"b\" parameters\n",
        "        loss.backward()\n",
        "        # Step 4 - Updates parameters using gradients and the learning rate\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Returns the loss\n",
        "        return loss.item()\n",
        "\n",
        "    # Returns the function that will be called inside the train loop\n",
        "    return perform_train_step_fn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zk-YqB4GZkXj"
      },
      "source": [
        "### Model Configuration V1"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run data preparation first"
      ],
      "metadata": {
        "id": "FgBmuXyNee0x"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "qdBJo7UeZkXk"
      },
      "outputs": [],
      "source": [
        "%run -i data_preparation/v0.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "gOdVpCSeZkXk",
        "outputId": "8e6d9104-07c8-429f-f866-bd07fe347699",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing model_configuration/v1.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile model_configuration/v1.py\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# Sets learning rate - this is \"eta\" ~ the \"n\" like Greek letter\n",
        "lr = 0.1\n",
        "\n",
        "torch.manual_seed(42)\n",
        "# Now we can create a model and send it at once to the device\n",
        "model = nn.Sequential(nn.Linear(1, 1)).to(device)\n",
        "\n",
        "# Defines a SGD optimizer to update the parameters (now retrieved directly from the model)\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
        "\n",
        "# Defines a MSE loss function\n",
        "loss_fn = nn.MSELoss(reduction='mean')\n",
        "\n",
        "# Creates the train_step function for our model, loss function and optimizer\n",
        "train_step_fn = make_train_step_fn(model, loss_fn, optimizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "dJH46Uw3ZkXk"
      },
      "outputs": [],
      "source": [
        "%run -i model_configuration/v1.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "SxafgQ7dZkXk",
        "outputId": "22b82c26-6768-4b10-9b8e-19688e17134d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function __main__.make_train_step_fn.<locals>.perform_train_step_fn(x, y)>"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>make_train_step_fn.&lt;locals&gt;.perform_train_step_fn</b><br/>def perform_train_step_fn(x, y)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/content/&lt;ipython-input-6-7a495872bccd&gt;</a>&lt;no docstring&gt;</pre></div>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "train_step_fn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4lDOt9GuZkXk"
      },
      "source": [
        "### Model Training V1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "GlrOLkUiZkXk",
        "outputId": "68cd7c97-868f-4186-811b-69bc8dde528b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing model_training/v1.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile model_training/v1.py\n",
        "\n",
        "# Defines number of epochs\n",
        "n_epochs = 1000\n",
        "\n",
        "losses = []\n",
        "\n",
        "# For each epoch...\n",
        "for epoch in range(n_epochs):\n",
        "    # Performs one train step and returns the corresponding loss\n",
        "    loss = train_step_fn(x_train_tensor, y_train_tensor)\n",
        "    losses.append(loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "3eCmzoqmZkXk"
      },
      "outputs": [],
      "source": [
        "%run -i model_training/v1.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "AgJRFLZ1ZkXk",
        "outputId": "65bfe61e-7640-4381-eab7-d2fcc94ca248",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OrderedDict([('0.weight', tensor([[1.9690]], device='cuda:0')), ('0.bias', tensor([1.0235], device='cuda:0'))])\n"
          ]
        }
      ],
      "source": [
        "# Checks model's parameters\n",
        "print(model.state_dict())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ggQ43Dh2ZkXk"
      },
      "source": [
        "# Dataset\n",
        "\n",
        "In PyTorch, a dataset is represented by a regular Python class that inherits from the `Dataset` class. You can think of it as a list of tuples, each tuple corresponding to one point **(features, label)**.\n",
        "\n",
        "The most fundamental methods it needs to implement are:\n",
        "\n",
        " __ init __(self):\n",
        "\n",
        " __ getitem__(self, index):\n",
        "\n",
        " __ len__(self):\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6YjaN56UZkXk"
      },
      "source": [
        "### Cell 2.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "CljuuwDaZkXk",
        "outputId": "9548b2ab-48bb-4a34-f333-e75d3ed1e21c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor([0.7713]), tensor([2.4745]))\n"
          ]
        }
      ],
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, x_tensor, y_tensor):\n",
        "        self.x = x_tensor\n",
        "        self.y = y_tensor\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return (self.x[index], self.y[index])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x)\n",
        "\n",
        "# Wait, is this a CPU tensor now? Why? Where is .to(device)?\n",
        "x_train_tensor = torch.from_numpy(x_train).float()\n",
        "y_train_tensor = torch.from_numpy(y_train).float()\n",
        "\n",
        "train_data = CustomDataset(x_train_tensor, y_train_tensor)\n",
        "print(train_data[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6W_dnp0zZkXl"
      },
      "source": [
        "## TensorDataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qmxj2R6-ZkXl"
      },
      "source": [
        "### Cell 2.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "uGDkDVzaZkXl",
        "outputId": "e4b7b6fb-7609-4bc5-af81-e85364c0bbea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor([0.7713], device='cuda:0'), tensor([2.4745], device='cuda:0'))\n"
          ]
        }
      ],
      "source": [
        "train_data = TensorDataset(x_train_tensor, y_train_tensor)\n",
        "print(train_data[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XH_us0daZkXl"
      },
      "source": [
        "## DataLoader\n",
        "\n",
        "Dataloader é uma classe dentro do Pytorch que seleciona uma fatia específica do dataset em questão.\n",
        "\n",
        "Será utilizado para o mini-batch dentro do gradient descent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1gsAtwMZkXl"
      },
      "source": [
        "### Cell 2.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "JYC4raOlZkXl"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(dataset=train_data, batch_size=16, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "tensor x\n",
        "\n",
        "tensor y"
      ],
      "metadata": {
        "id": "GGWXJQmWYQTE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "scrolled": false,
        "id": "YmwoxID7ZkXl",
        "outputId": "08f58bba-9b02-4b48-8451-246964c9e5f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([[0.2809],\n",
              "         [0.3253],\n",
              "         [0.1560],\n",
              "         [0.5924],\n",
              "         [0.0651],\n",
              "         [0.8872],\n",
              "         [0.4938],\n",
              "         [0.0055],\n",
              "         [0.1409],\n",
              "         [0.0885],\n",
              "         [0.1849],\n",
              "         [0.7290],\n",
              "         [0.8662],\n",
              "         [0.3117],\n",
              "         [0.6842],\n",
              "         [0.1987]], device='cuda:0'),\n",
              " tensor([[1.5846],\n",
              "         [1.8057],\n",
              "         [1.2901],\n",
              "         [2.1687],\n",
              "         [1.1559],\n",
              "         [2.8708],\n",
              "         [1.9060],\n",
              "         [1.0632],\n",
              "         [1.1211],\n",
              "         [1.0708],\n",
              "         [1.5888],\n",
              "         [2.4927],\n",
              "         [2.6805],\n",
              "         [1.7637],\n",
              "         [2.3492],\n",
              "         [1.2654]], device='cuda:0')]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "next(iter(train_loader))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jo6mUajxZkXq"
      },
      "source": [
        "### Data Preparation V1\n",
        "\n",
        "we need to add both `Dataset` and `DataLoader` elements into our data preparation part of the code.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "MUiVKETjZkXq",
        "outputId": "309c51b7-5d6b-4603-faec-f26fb99a7cbb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing data_preparation/v1.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile data_preparation/v1.py\n",
        "\n",
        "# Our data was in Numpy arrays, but we need to transform them into PyTorch's Tensors\n",
        "x_train_tensor = torch.from_numpy(x_train).float()\n",
        "y_train_tensor = torch.from_numpy(y_train).float()\n",
        "\n",
        "# Builds Dataset\n",
        "train_data = TensorDataset(x_train_tensor, y_train_tensor)\n",
        "\n",
        "# Builds DataLoader\n",
        "train_loader = DataLoader(dataset=train_data, batch_size=16, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "FzDCHV9EZkXq"
      },
      "outputs": [],
      "source": [
        "%run -i data_preparation/v1.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6sabSfrSZkXq"
      },
      "source": [
        "### Model Training V2\n",
        "\n",
        "we need to incorporate the **mini-batch** gradient descent logic into our **model training** part of the code.\n",
        "\n",
        "But we need to run the model configuration first.\n",
        "\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "cxXsQgk5ZkXr"
      },
      "outputs": [],
      "source": [
        "%run -i model_configuration/v1.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "vaeEyrpXZkXr",
        "outputId": "a57af842-acef-4a67-bf89-99b8be53156b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing model_training/v2.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile model_training/v2.py\n",
        "\n",
        "# Defines number of epochs\n",
        "n_epochs = 1000\n",
        "\n",
        "losses = []\n",
        "\n",
        "# For each epoch...\n",
        "for epoch in range(n_epochs):\n",
        "    # inner loop\n",
        "    mini_batch_losses = []\n",
        "    for x_batch, y_batch in train_loader:\n",
        "        # the dataset \"lives\" in the CPU, so do our mini-batches\n",
        "        # therefore, we need to send those mini-batches to the\n",
        "        # device where the model \"lives\"\n",
        "        x_batch = x_batch.to(device)\n",
        "        y_batch = y_batch.to(device)\n",
        "\n",
        "        # Performs one train step and returns the corresponding loss\n",
        "        # for this mini-batch\n",
        "        mini_batch_loss = train_step_fn(x_batch, y_batch)\n",
        "        mini_batch_losses.append(mini_batch_loss)\n",
        "\n",
        "    # Computes average loss over all mini-batches - that's the epoch loss\n",
        "    loss = np.mean(mini_batch_losses)\n",
        "\n",
        "    losses.append(loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "vm9IfmrBZkXr"
      },
      "outputs": [],
      "source": [
        "%run -i model_training/v2.py"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "it is time to check if our code still works well:\n"
      ],
      "metadata": {
        "id": "5lMaEXBTgte6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "_Y7zWVukZkXr",
        "outputId": "16d51f27-28fd-4c6d-af6c-6bce62fe253a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OrderedDict([('0.weight', tensor([[1.9696]], device='cuda:0')), ('0.bias', tensor([1.0243], device='cuda:0'))])\n"
          ]
        }
      ],
      "source": [
        "# Checks model's parameters\n",
        "print(model.state_dict())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#All execution\n",
        "\n",
        "%run -i data_preparation/v1.py\n",
        "%run -i model_configuration/v1.py\n",
        "%run -i model_training/v2.py\n",
        "\n"
      ],
      "metadata": {
        "id": "zB6U5qe2hkUE"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZlUOPTNVZkXr"
      },
      "source": [
        "## Mini-Batch Inner Loop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9_or2XLZkXs"
      },
      "source": [
        "### Helper Function #2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "DcuHMJOfZkXs"
      },
      "outputs": [],
      "source": [
        "def mini_batch(device, data_loader, step_fn):\n",
        "    mini_batch_losses = []\n",
        "    for x_batch, y_batch in data_loader:\n",
        "        x_batch = x_batch.to(device)\n",
        "        y_batch = y_batch.to(device)\n",
        "\n",
        "        mini_batch_loss = step_fn(x_batch, y_batch)\n",
        "        mini_batch_losses.append(mini_batch_loss)\n",
        "\n",
        "    loss = np.mean(mini_batch_losses)\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7C6gwzvuZkXs"
      },
      "source": [
        "### Model Training V3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "yFsYgwQqZkXs"
      },
      "outputs": [],
      "source": [
        "%run -i data_preparation/v1.py\n",
        "%run -i model_configuration/v1.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "mLcCS7GDZkXs",
        "outputId": "fbe2a268-83ef-437f-b919-e53598fe4c21",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing model_training/v3.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile model_training/v3.py\n",
        "\n",
        "# Defines number of epochs\n",
        "n_epochs = 200\n",
        "\n",
        "losses = []\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    # inner loop\n",
        "    #call mini_batch helper function\n",
        "    loss = mini_batch(device, train_loader, train_step_fn)\n",
        "    losses.append(loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "dDoNNYpUZkXs"
      },
      "outputs": [],
      "source": [
        "%run -i model_training/v3.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "h1r1TF7PZkXs",
        "outputId": "9cec6041-f974-4120-93d1-e93988cfd07a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OrderedDict([('0.weight', tensor([[1.9684]], device='cuda:0')), ('0.bias', tensor([1.0219], device='cuda:0'))])\n"
          ]
        }
      ],
      "source": [
        "# Checks model's parameters\n",
        "print(model.state_dict())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q8m_ao66ZkXt"
      },
      "source": [
        "## Random Split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afFAzNOhZkXt"
      },
      "source": [
        "### Data Preparation V2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "PUGq-EvPZkXt",
        "outputId": "778ba29b-2ff9-4cb2-aa47-e77d0f1cc55a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing data_preparation/v2.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile data_preparation/v2.py\n",
        "\n",
        "torch.manual_seed(13)\n",
        "\n",
        "# Builds tensors from numpy arrays BEFORE split\n",
        "x_tensor = torch.from_numpy(x).float()\n",
        "y_tensor = torch.from_numpy(y).float()\n",
        "\n",
        "# Builds dataset containing ALL data points\n",
        "dataset = TensorDataset(x_tensor, y_tensor)\n",
        "\n",
        "# Performs the split\n",
        "ratio = .8\n",
        "n_total = len(dataset)\n",
        "n_train = int(n_total * ratio)\n",
        "n_val = n_total - n_train\n",
        "\n",
        "train_data, val_data = random_split(dataset, [n_train, n_val])\n",
        "\n",
        "# Builds a loader of each set\n",
        "train_loader = DataLoader(dataset=train_data, batch_size=16, shuffle=True)\n",
        "val_loader = DataLoader(dataset=val_data, batch_size=16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "bc1-kyEbZkXt"
      },
      "outputs": [],
      "source": [
        "%run -i data_preparation/v2.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8imtzntZkXt"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nwv0RJqcZkXt"
      },
      "source": [
        "### Helper Function #3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "EosefEruZkXt"
      },
      "outputs": [],
      "source": [
        "def make_val_step_fn(model, loss_fn):\n",
        "    # Builds function that performs a step in the validation loop\n",
        "    def perform_val_step_fn(x, y):\n",
        "        # Sets model to EVAL mode\n",
        "        model.eval()\n",
        "\n",
        "        # Step 1 - Computes our model's predicted output - forward pass\n",
        "        yhat = model(x)\n",
        "        # Step 2 - Computes the loss\n",
        "        loss = loss_fn(yhat, y)\n",
        "        # There is no need to compute Steps 3 and 4, since we don't update parameters during evaluation\n",
        "        return loss.item()\n",
        "\n",
        "    return perform_val_step_fn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GjRcxFQgZkXt"
      },
      "source": [
        "### Model Configuration V2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "PI4T1Zf9ZkXu",
        "outputId": "46479a02-12d3-43bd-b1ae-b2d2dc8978a6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing model_configuration/v2.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile model_configuration/v2.py\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# Sets learning rate - this is \"eta\" ~ the \"n\" like Greek letter\n",
        "lr = 0.1\n",
        "\n",
        "torch.manual_seed(42)\n",
        "# Now we can create a model and send it at once to the device\n",
        "model = nn.Sequential(nn.Linear(1, 1)).to(device)\n",
        "\n",
        "# Defines a SGD optimizer to update the parameters (now retrieved directly from the model)\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
        "\n",
        "# Defines a MSE loss function\n",
        "loss_fn = nn.MSELoss(reduction='mean')\n",
        "\n",
        "# Creates the train_step function for our model, loss function and optimizer\n",
        "train_step_fn = make_train_step_fn(model, loss_fn, optimizer)\n",
        "\n",
        "# Creates the val_step function for our model and loss function\n",
        "val_step_fn = make_val_step_fn(model, loss_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "HUqzq-fMZkXu"
      },
      "outputs": [],
      "source": [
        "%run -i model_configuration/v2.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQ934zyjZkXu"
      },
      "source": [
        "### Model Training V4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "H7J5SUkeZkXu",
        "outputId": "01e93d90-d347-49f2-93a0-830c23adf5d1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing model_training/v4.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile model_training/v4.py\n",
        "\n",
        "# Defines number of epochs\n",
        "n_epochs = 200\n",
        "\n",
        "losses = []\n",
        "val_losses = []\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    # inner loop\n",
        "    loss = mini_batch(device, train_loader, train_step_fn)\n",
        "    losses.append(loss)\n",
        "\n",
        "    # VALIDATION\n",
        "    # no gradients in validation = no_grad()!\n",
        "    with torch.no_grad():\n",
        "        val_loss = mini_batch(device, val_loader, val_step_fn)\n",
        "        val_losses.append(val_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UQnPmUSbZkXu"
      },
      "outputs": [],
      "source": [
        "%run -i model_training/v4.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NjuIqrNqZkXu"
      },
      "outputs": [],
      "source": [
        "# Checks model's parameters\n",
        "print(model.state_dict())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wajrSZ0xZkXu"
      },
      "source": [
        "## Plotting Losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YdESEfHEZkXv"
      },
      "outputs": [],
      "source": [
        "fig = plot_losses(losses, val_losses)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14wYWhvmZkXv"
      },
      "source": [
        "# TensorBoard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nNv-HivjZkXv"
      },
      "outputs": [],
      "source": [
        "# tensorboard_cleanup()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_3uFaWblZkXv"
      },
      "outputs": [],
      "source": [
        "if IS_BINDER:\n",
        "    display(TB_LINK)\n",
        "else:\n",
        "    %load_ext tensorboard\n",
        "    %tensorboard --logdir runs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RgoGCCQvZkXv"
      },
      "source": [
        "## SummaryWriter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z9g1-nCuZkXv"
      },
      "outputs": [],
      "source": [
        "writer = SummaryWriter('runs/test')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xGXcQPbZkXv"
      },
      "source": [
        "## add_graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1EDro70NZkXv"
      },
      "outputs": [],
      "source": [
        "writer.add_graph(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-qNiJa7kZkXv"
      },
      "outputs": [],
      "source": [
        "# Fetching a tuple of feature (sample_x) and label (sample_y)\n",
        "sample_x, sample_y = next(iter(train_loader))\n",
        "\n",
        "# Since our model was sent to device, we need to do the same with the data\n",
        "# Even here, both model and data need to be on the same device!\n",
        "writer.add_graph(model, sample_x.to(device))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4AokXz3ZkXw"
      },
      "source": [
        "## add_scalars"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b_7wBMbCZkXw"
      },
      "outputs": [],
      "source": [
        "writer.add_scalars('loss', {'training': loss, 'validation': val_loss}, epoch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YjTd0elzZkXw"
      },
      "source": [
        "### Model Configuration V3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FMA83rHnZkXw"
      },
      "outputs": [],
      "source": [
        "%run -i data_preparation/v2.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j6qtPvzsZkXw"
      },
      "outputs": [],
      "source": [
        "%%writefile model_configuration/v3.py\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# Sets learning rate - this is \"eta\" ~ the \"n\" like Greek letter\n",
        "lr = 0.1\n",
        "\n",
        "torch.manual_seed(42)\n",
        "# Now we can create a model and send it at once to the device\n",
        "model = nn.Sequential(nn.Linear(1, 1)).to(device)\n",
        "\n",
        "# Defines a SGD optimizer to update the parameters (now retrieved directly from the model)\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
        "\n",
        "# Defines a MSE loss function\n",
        "loss_fn = nn.MSELoss(reduction='mean')\n",
        "\n",
        "# Creates the train_step function for our model, loss function and optimizer\n",
        "train_step_fn = make_train_step_fn(model, loss_fn, optimizer)\n",
        "\n",
        "# Creates the val_step function for our model and loss function\n",
        "val_step_fn = make_val_step_fn(model, loss_fn)\n",
        "\n",
        "# Creates a Summary Writer to interface with TensorBoard\n",
        "writer = SummaryWriter('runs/simple_linear_regression')\n",
        "\n",
        "# Fetches a single mini-batch so we can use add_graph\n",
        "x_sample, y_sample = next(iter(train_loader))\n",
        "writer.add_graph(model, x_sample.to(device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-1s6j1EOZkXw"
      },
      "outputs": [],
      "source": [
        "%run -i model_configuration/v3.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40wWOkSEZkXw"
      },
      "source": [
        "### Model Training V5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dNDBo2w2ZkXw"
      },
      "outputs": [],
      "source": [
        "%%writefile model_training/v5.py\n",
        "\n",
        "# Defines number of epochs\n",
        "n_epochs = 200\n",
        "\n",
        "losses = []\n",
        "val_losses = []\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    # inner loop\n",
        "    loss = mini_batch(device, train_loader, train_step_fn)\n",
        "    losses.append(loss)\n",
        "\n",
        "    # VALIDATION\n",
        "    # no gradients in validation!\n",
        "    with torch.no_grad():\n",
        "        val_loss = mini_batch(device, val_loader, val_step_fn)\n",
        "        val_losses.append(val_loss)\n",
        "\n",
        "    # Records both losses for each epoch under the main tag \"loss\"\n",
        "    writer.add_scalars(main_tag='loss',\n",
        "                       tag_scalar_dict={'training': loss, 'validation': val_loss},\n",
        "                       global_step=epoch)\n",
        "\n",
        "# Closes the writer\n",
        "writer.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LwyR9zrQZkXx"
      },
      "outputs": [],
      "source": [
        "%run -i model_training/v5.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ruFXav5XZkXx"
      },
      "outputs": [],
      "source": [
        "# Checks model's parameters\n",
        "print(model.state_dict())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1XtehwoVZkXx"
      },
      "source": [
        "# Saving and Loading Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxPPUWyMZkXx"
      },
      "source": [
        "## Saving"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EmZN8wijZkXx"
      },
      "source": [
        "### Cell 2.4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0w_N5UUBZkXx"
      },
      "outputs": [],
      "source": [
        "checkpoint = {'epoch': n_epochs,\n",
        "              'model_state_dict': model.state_dict(),\n",
        "              'optimizer_state_dict': optimizer.state_dict(),\n",
        "              'loss': losses,\n",
        "              'val_loss': val_losses}\n",
        "\n",
        "torch.save(checkpoint, 'model_checkpoint.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKXcgiIEZkXx"
      },
      "source": [
        "## Resuming Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4Ury2k_ZkXx"
      },
      "source": [
        "### Cell 2.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uk-hqiLTZkXx"
      },
      "outputs": [],
      "source": [
        "%run -i data_preparation/v2.py\n",
        "%run -i model_configuration/v3.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NazCzJEBZkXx"
      },
      "outputs": [],
      "source": [
        "print(model.state_dict())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aeClJM2AZkXx"
      },
      "source": [
        "### Cell 2.6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t68UT2SLZkXy"
      },
      "outputs": [],
      "source": [
        "checkpoint = torch.load('model_checkpoint.pth', weights_only=False)\n",
        "\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "\n",
        "saved_epoch = checkpoint['epoch']\n",
        "saved_losses = checkpoint['loss']\n",
        "saved_val_losses = checkpoint['val_loss']\n",
        "\n",
        "model.train() # always use TRAIN for resuming training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wbfyG_26ZkXy"
      },
      "outputs": [],
      "source": [
        "print(model.state_dict())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9IHf-xwJZkXy"
      },
      "source": [
        "### Cell 2.7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rm5CMBh2ZkXy"
      },
      "outputs": [],
      "source": [
        "%run -i model_training/v5.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vWBy_VrdZkXy"
      },
      "outputs": [],
      "source": [
        "print(model.state_dict())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EEL0X-mmZkXy"
      },
      "outputs": [],
      "source": [
        "fig = plot_resumed_losses(saved_epoch, saved_losses, saved_val_losses, n_epochs, losses, val_losses)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BGOxPuSUZkXy"
      },
      "source": [
        "## Deploying / Making Predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mA7h95vZkXy"
      },
      "source": [
        "### Cell 2.8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4fMkQG93ZkXy"
      },
      "outputs": [],
      "source": [
        "%run -i model_configuration/v3.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CyyGgu_WZkXy"
      },
      "source": [
        "### Cell 2.9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ty1e99ifZkXz"
      },
      "outputs": [],
      "source": [
        "checkpoint = torch.load('model_checkpoint.pth', weights_only=False)\n",
        "\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "print(model.state_dict())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BG7HXTTiZkXz"
      },
      "source": [
        "### Cell 2.10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7MMjTFqHZkXz"
      },
      "outputs": [],
      "source": [
        "new_inputs = torch.tensor([[.20], [.34], [.57]])\n",
        "\n",
        "model.eval() # always use EVAL for fully trained models!\n",
        "model(new_inputs.to(device))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRbSPSDpZkXz"
      },
      "source": [
        "# Putting It All Together"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vuvGleeTZkXz"
      },
      "outputs": [],
      "source": [
        "# %load data_preparation/v2.py\n",
        "\n",
        "torch.manual_seed(13)\n",
        "\n",
        "# Builds tensors from numpy arrays BEFORE split\n",
        "x_tensor = torch.from_numpy(x).float()\n",
        "y_tensor = torch.from_numpy(y).float()\n",
        "\n",
        "# Builds dataset containing ALL data points\n",
        "dataset = TensorDataset(x_tensor, y_tensor)\n",
        "\n",
        "# Performs the split\n",
        "ratio = .8\n",
        "n_total = len(dataset)\n",
        "n_train = int(n_total * ratio)\n",
        "n_val = n_total - n_train\n",
        "\n",
        "train_data, val_data = random_split(dataset, [n_train, n_val])\n",
        "\n",
        "# Builds a loader of each set\n",
        "train_loader = DataLoader(dataset=train_data, batch_size=16, shuffle=True)\n",
        "val_loader = DataLoader(dataset=val_data, batch_size=16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_aFvcHW8ZkXz"
      },
      "outputs": [],
      "source": [
        "# %load model_configuration/v3.py\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# Sets learning rate - this is \"eta\" ~ the \"n\" like Greek letter\n",
        "lr = 0.1\n",
        "\n",
        "torch.manual_seed(42)\n",
        "# Now we can create a model and send it at once to the device\n",
        "model = nn.Sequential(nn.Linear(1, 1)).to(device)\n",
        "\n",
        "# Defines a SGD optimizer to update the parameters (now retrieved directly from the model)\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
        "\n",
        "# Defines a MSE loss function\n",
        "loss_fn = nn.MSELoss(reduction='mean')\n",
        "\n",
        "# Creates the train_step function for our model, loss function and optimizer\n",
        "train_step_fn = make_train_step_fn(model, loss_fn, optimizer)\n",
        "\n",
        "# Creates the val_step function for our model and loss function\n",
        "val_step_fn = make_val_step_fn(model, loss_fn)\n",
        "\n",
        "# Creates a Summary Writer to interface with TensorBoard\n",
        "writer = SummaryWriter('runs/simple_linear_regression')\n",
        "\n",
        "# Fetches a single mini-batch so we can use add_graph\n",
        "x_sample, y_sample = next(iter(train_loader))\n",
        "writer.add_graph(model, x_sample.to(device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2FvknrlcZkXz"
      },
      "outputs": [],
      "source": [
        "# %load model_training/v5.py\n",
        "\n",
        "# Defines number of epochs\n",
        "n_epochs = 200\n",
        "\n",
        "losses = []\n",
        "val_losses = []\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    # inner loop\n",
        "    loss = mini_batch(device, train_loader, train_step_fn)\n",
        "    losses.append(loss)\n",
        "\n",
        "    # VALIDATION\n",
        "    # no gradients in validation!\n",
        "    with torch.no_grad():\n",
        "        val_loss = mini_batch(device, val_loader, val_step_fn)\n",
        "        val_losses.append(val_loss)\n",
        "\n",
        "    # Records both losses for each epoch under the main tag \"loss\"\n",
        "    writer.add_scalars(main_tag='loss',\n",
        "                       tag_scalar_dict={'training': loss, 'validation': val_loss},\n",
        "                       global_step=epoch)\n",
        "\n",
        "# Closes the writer\n",
        "writer.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OtKLioz-ZkXz"
      },
      "outputs": [],
      "source": [
        "print(model.state_dict())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o62wz8LFZkX0"
      },
      "source": [
        "### Weird plots in TensorBoard?\n",
        "\n",
        "Run this if you want to clean up a previous run and start fresh with TensorBoard :-)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PyA9VHTtZkX0"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "\n",
        "shutil.rmtree('./runs/simple_linear_regression/', ignore_errors=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fg2nO828ZkX0"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}